---
title: "Day2 AI 不是魔法，是規則的堆疊"
day: 2
slug: day-02-ai-not-magic-rule-stacking
date: 2025-09-15T16:03:32+08:00
tags: [AI, CleanArchitecture, PromptEngineering, SoftwareDesign]
summary: "AI 輸出品質取決於你顯性化的規則，而非神秘魔法。"
draft: false
---

# Day2 AI 不是魔法，是規則的堆疊

## 今日主題：

很多人第一次接觸 AI，覺得「哇，它好像會『理解』我」，但實際上它比較像一座巨大自助餐：你端上「清楚分類好的食材（結構化的輸入）」它就能幫你快速排出看起來專業的菜；你把一坨混在一起的剩菜丟上去，它還是會端出東西，但多半四不像。

這就像蓋積木城堡：

- 你以為它神奇，其實它只是「很多小積木依規則堆成穩固形狀」。
- 差的城堡：直接亂堆 → 一加高就倒。
- 好的城堡：先分顏色 / 類型 / 功能，再分層堆疊。

AI 給出的東西，品質往往不是「模型多神」，而是「你前面有沒有整理出價值密度高的訊息」。**架構思維就是幫助你把原本混亂的需求、資料、意圖，轉成 AI 能理解且能維護的『穩定積木』。**

## 範例故事：

一個 Side Project 小團隊：PM、兩位工程師，加上一位想幫忙寫部落格的實習生。目標：用 AI 協助產出一系列「功能介紹 + 使用教學」文章。

第一週的慘況：

- PM 丟一段雜訊訊息到群組：「可以幫我生一篇介紹我們搜尋功能的文章？順便提一下快取、還有為什麼有時候結果慢，然後語氣要親切一點，標題酷一點。」
- 實習生把這整段複製貼給模型：「幫我寫。」→ 輸出 1200 字，看似完整，實際：術語亂用、跟現在版本 UI 不符、性能解釋錯一半。
- 工程師花 40 分鐘修，再丟回模型請它「調整語氣」→ 又走樣。

第二週改變：我讓團隊先做「輸入拆解」：

1. 文章目的：教育使用者搜尋功能的價值（不是寫 release note）。
2. 讀者層級：初次評估產品的潛在用戶（非既有技術使用者）。
3. 結構（固定模板）：
   - 痛點場景（使用者現在的困擾）
   - 我們的功能如何介入
   - 一個實際操作流程 (Step 1-3)
   - 速度/準確性如何達成（含 cache 與搜尋策略一句話解釋）
   - 行動呼籲（CTA）
4. 關鍵事實表（Fact Sheet）：
   - 最大索引更新頻率：5 分鐘
   - 快取失效策略：LRU + TTL 60s
   - 可能變慢的兩種情況：初次預熱 / 大量篩選條件組合
5. 語氣規則：
   - 禁用詞：『革命性』『顛覆世界』
   - 允許語氣：專業 + 友善 + 具體

然後我們給 AI 的提示變成：
「請依下列結構寫一篇 800 字內的教學文章。若 Fact Sheet 未提及，不自行推測技術。若讀者可能誤解性能限制，請加一段『為什麼有時慢』的說明。」

結果：

- 初稿可用度：從 40% → 85%。
- 工程師改寫時間：40 分鐘 → 8 分鐘（主要微調術語 + 刪除冗語）。
- PM 覺得「AI 終於不是在製造更多工作」。

差別不是模型升級，而是：輸入被拆成「可組合、可審核、可重複的規則」。這正是架構思維的影子：把意圖（Use Case）、事實（Entities / Facts）、呈現（Interface / Presenter）分離。AI 只是根據這些規則重新排列語言。你提供的規則越清楚，輸出越接近你要的價值。

## 在程式中的應用是什麼？

當我們說「AI 是規則的堆疊」，在程式世界其實對應到兩層：

1. 模型內部：大量參數記住統計關聯（不是今日主角）。
2. 你外部包起來的『語意管線 (Prompt / Context Orchestration)』：決定最後輸出是否穩定可用。

Clean Architecture 的觀念可以直接移植到「讓 AI 幫你完成一段業務工作」：

| Clean Arch 元素       | 在 AI 協作中的對應                                      | 目的                             |
| --------------------- | ------------------------------------------------------- | -------------------------------- |
| Entity (核心業務概念) | 結構化 Fact Sheet / Domain 物件                         | 穩定、不隨表達方式改變的事實來源 |
| Use Case (應用邏輯)   | 這次要產出的任務意圖拆解 (目的/讀者/長度/風格/禁止事項) | 將模糊需求轉為可檢查的規則       |
| Interface Adapter     | Prompt 模板 / 權重化段落 / 範例對照                     | 控制輸入排列順序與格式一致性     |
| Framework & Driver    | API 呼叫層 / LLM SDK / Cache                            | 技術細節放外層，避免滲入語意規則 |

一個常見錯誤：直接把 Controller 收到的原始使用者敘述丟進模型，希望它「自己想辦法」。結果：

- 回傳內容混入錯誤假設（Hallucination）。
- 多次呼叫風格漂移。
- 無法對差異做 diff（因為沒有結構化段落）。

改成架構化流程：

1. 驗證輸入：缺必要欄位（目的、讀者）就回補問答。
2. 正規化：將輸入映射到內部 Domain 結構（如 ArticleIntent { audience, goal, tone, constraints }）。
3. 組合 Prompt：固定框架 + 動態欄位插槽 + Fact Sheet 附錄。
4. 後處理：檢查必備段落是否都出現，缺就二次補全文段（不是整篇重生）。
5. 緩存：相同 Fact Sheet + Intent Hash 若已生成，直接返回（穩定輸出 → 減少成本）。

這其實就是在用程式把「規則」顯性化：

- 模型：語言統計黑盒。
- 你：規則編排者（Sequence + Structure）。
- 架構：保障規則可以被復用、測試、替換實作（換模型不重寫業務）。

小結論：當你把 AI 當函式呼叫而不是魔法占卜，Clean Architecture 給你的分層讓「語意輸入」也擁有與程式碼類似的可演進性。

## 小結與一個思考問題：

今天我們把「AI 不是魔法」拆開看：它只是在大量規則（顯性 + 隱性統計）上進行重新排列。你能掌控的，是顯性那一層——輸入的結構化、意圖的清晰度、事實資料的可驗證性。Clean Architecture 幫我們把這些要素分開存放，避免「需求改一次 → 全部 prompt 重寫」。

核心帶走：

- 產出品質 ＝ 模型能力 × (輸入規則清晰度)^2 （近似概念）
- 無法測的輸入 → 無法複製 → 無法優化
- 把需求拆成可命名欄位，是最便宜的效能升級

思考題（給明天的鋪陳）：
如果我們要讓 AI 協助「在多人協作專案中生成重複類型的說明文件」，你會怎麼定義一份『最小可測的輸入規則集合 (Minimal Prompt Contract)』？它應該包含哪些欄位，哪些欄位可以延後到生成後再補？

歡迎你先寫下 5 個欄位名稱，明天（Day3）我們會把它轉成可以程式化驗證的結構。
